# %% [markdown]
# # Author: Katelyn M Campbell
# # Assignment: Capstone Milestone 3- Random Forest
# # Class: DSC-580
# # Date: 4/23/2025

# %%
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
import statsmodels.stats.api as sms
import scipy.stats as stats
import statistics
import numpy as np
from sklearn import linear_model
from sklearn.model_selection import train_test_split
import sklearn
import warnings
from sklearn.impute import KNNImputer
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import f1_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score, cross_validate
from sklearn.metrics import mean_squared_error, r2_score
import tensorflow as tf
import os
import math
import graphviz
from tensorflow.keras.models import Sequential
from keras.models import Sequential
from keras.layers import Dense
from tensorflow.keras.utils import plot_model
from tensorflow.keras.layers import Dense
from sklearn.pipeline import Pipeline
from sklearn.tree import plot_tree
from graphviz import Digraph
import matplotlib.image as mpimg
from dash import Dash, dcc, html, Input, Output
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import time
from urllib.request import urlopen
#loads necessary packages

# %% [markdown]
# # Help
# 
# ### Purpose:
# To build Random Forest models and generate reports.
# 
# ### How to Run:
# - Run each cell in order (previous generated information may not be captured otherwise).
# - Modify the data, model and their features as needed.
# 
# ### What You'll Get:
# - Printed and saved reports of MSE, R-squared, and cross validation results (as .txt files).
# - Printed and saved observed vs. predicted value graphs (as PNG images).
# 
# ### Functions Included:
# - pd.read_csv()
# - train_test_split()
# - RandomForestRegressor()
# - fit()
# - predict()
# - scatter(), as well as other releavant graphing functions
# - mean_squared_error()
# - r2_score()
# - cross_validate()
# - print()
# 
# Please use the `help(function_name)` in a new cell to learn more about any functions.
# 
# Additional note: The interpretation is based on the model last generated by the developer. Any newly completed iterations will change the training and testing split of the data, which may impact the results. Any modifications also would alter the results. New interpretations would be required.

# %%
def log_step(step_name):
 print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] {step_name}")
#logs when each step was ran

# %%
# option to upload url data
from dash import Dash, html, dcc, Output, Input
import pandas as pd
import dash
import json

app = Dash(__name__)
server = app.server

app.layout = html.Div([
    html.H1("Load Data from URL"),
    dcc.Input(
        id='url-input',
        type='text',
        placeholder='Enter the URL to load (.csv or .json)',
        style={'width': '60%'}
    ),
    html.Button('Load', id='load-button'),
    html.Div(id='data-output')
])

@app.callback(
    Output('data-output', 'children'),
    Input('load-button', 'n_clicks'),
    dash.dependencies.State('url-input', 'value')
)
def load_data(n_clicks, url):
    if not url:
        return "Please enter a URL."

    try:
        if url.endswith('.csv'):
            df = pd.read_csv(url)
            return html.Div([
                html.P("CSV loaded successfully."),
                html.Pre(df.head().to_string())
            ])
        elif url.endswith('.json'):
            df = pd.read_json(url)
            return html.Div([
                html.P("JSON loaded successfully."),
                html.Pre(df.head().to_string())
            ])
        else:
            return "Unsupported file type. Please enter a .csv or .json URL."
    except Exception as e:
        return f"An error occurred: {str(e)}"

if __name__ == "__main__":
    app.run_server(debug=True)

# for reading URL data

# %% [markdown]
# No URL was uploaded, so the test expectations were met.

# %%
log_step("Loading Data")
data_clean = pd.read_csv("data_clean.csv")
data_nomean_out = pd.read_csv("data_nomean_out.csv")
data_nomedian_out = pd.read_csv("data_nomedian_out.csv")
data_log = pd.read_csv("data_log.csv")
print("Data Loaded")
#loads data and logs time
#can replace path for different data

# %%
try:
    data = pd.read_csv("data_clean.csv")
    assert not data.empty, "Loaded dataframe is empty."
    print("Data loaded successfully and is not empty.")
except FileNotFoundError:
    print("File not found. Check the file path.")
except pd.errors.ParserError:
    print("Failed to parse the file. Check format.")
except AssertionError as ae:
    print(f"Data issue: {ae}")
except Exception as e:
    print(f"Unexpected error: {e}")
    # tests loading data

# %% [markdown]
# The data did upload and no error codes were risen, showing the test met expectations.

# %% [markdown]
# ## Model

# %%
log_step("Analyzing Data")
#logs time step completed

# %%
X =data_clean['COVID-19 doses (daily)']
y = data_clean['Daily new confirmed deaths due to COVID-19']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_mean =data_nomean_out['COVID-19 doses (daily, no outliers)']
y_mean = data_nomean_out['Daily new confirmed deaths due to COVID-19 (no outliers)']
X_mean_train, X_mean_test, y_mean_train, y_mean_test = train_test_split(X_mean, y_mean, test_size=0.2, random_state=42)

X_median =data_nomedian_out['COVID-19 doses (daily, no outliers)']
y_median = data_nomedian_out['Daily new confirmed deaths due to COVID-19 (no outliers)']
X_median_train, X_median_test, y_median_train, y__median_test = train_test_split(X_median, y_median, test_size=0.2, random_state=42)

X_log =data_log['COVID-19 doses (daily)']
y_log = data_log['Daily new confirmed deaths due to COVID-19']
X_log_train, X_log_test, y_log_train, y__log_test = train_test_split(X_log, y_log, test_size=0.2, random_state=42)
#trains original data, no outliers based on mean, no outliers based on median, and log data sets (Sarahjane3102, 2022)

# %%
try:
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    total_rows = len(X)
    train_rows = len(X_train)
    test_rows = len(X_test)

    if train_rows + test_rows == total_rows:
        print("Train-test split successful. Row count is consistent.")
    else:
        print(f"Train-test split mismatch. Expected {total_rows}, got {train_rows + test_rows}.")
    if X_train.index.intersection(X_test.index).any():
        print("Overlap found between training and test data.")
    else:
        print("No overlap between train and test sets.")

except Exception as e:
    print(f"Error during train-test split validation: {e}")
# test train-test split

# %% [markdown]
# The data was split into training and testing groups, with consistent row count. There was no overlap found between the sets, which meets test expectations.

# %%
regressor = RandomForestRegressor(n_estimators=10, random_state=0, oob_score=False)
regressor.fit(X_train.values.reshape(-1, 1), y_train)
predictions_RF = regressor.predict(X_test.values.reshape(-1, 1))
#creates model with original data (GeeksforGeeks, 2025)

# %%
regressor_mean = RandomForestRegressor(n_estimators=10, random_state=0, oob_score=False)
regressor_mean.fit(X_mean_train.values.reshape(-1, 1), y_mean_train)
predictions_RF_mean = regressor_mean.predict(X_mean_test.values.reshape(-1, 1))
# creates model with outliers removed by standard deviations away (GeeksforGeeks, 2025)

# %%
regressor_median = RandomForestRegressor(n_estimators=10, random_state=0, oob_score=False)
regressor_median.fit(X_median_train.values.reshape(-1, 1), y_train)
predictions_RF_median = regressor_median.predict(X_median_test.values.reshape(-1,1))
#generates model with outliers removed by IQR (GeeksforGeeks, 2025)

# %%
regressor_log = RandomForestRegressor(n_estimators=10, random_state=0, oob_score=False)
regressor_log.fit(X_log_train.values.reshape(-1, 1), y_log_train)
predictions_RF_log = regressor_log.predict(X_log_test.values.reshape(-1, 1))
# generates model with logarithmic transformed data (GeeksforGeeks, 2025)

# %%
try:
    regressor.fit(X_train.values.reshape(-1, 1), y_train)
    print("Model trained successfully.")
    test_predict = regressor.predict(X_test.values.reshape(-1, 1))
    print("Model predicted successfully.")
    if len(test_predict) == len(X_test):
        print("Prediction output shape is correct.")
    else:
        print("Prediction output shape mismatch.")
except Exception as e:
    print(f"Model training or predicting failed: {e}")
# tests model fit and predictions

# %% [markdown]
# The model was able to be trained and generate predictins. The shape of the predictions is correct, which meets test expectations.

# %%
log_step("Data Analyzed")
#prints that step was completed

# %% [markdown]
# Three models were chosen to compare and analyze which performed the best.
# These included the Poisson regression, Random Forest, and Deep Neural
# Networks. Overall, the ideal is to see three differing styles of approaches to
# modeling, with different levels of computational complexity. The dependent
# variable in the model is the daily new confirmed deaths due to COVID-19, and
# the independent variable is the daily new COVID-19 doses. Eighty percent of the
# data will be used to train, and twenty percent will be used as testing data. All
# data sets created, (the original observations, observations without outliers based
# on standard deviations away and interquartile range away, and log
# transformation), will be ran through the models and compared.
# 
# A Random Forest model involves averaging multiple models into one, which is an
# ensemble learning method (Fandohan et al., 2022). Deep Neural Networks, on
# the other hand, have many hidden layers that learn the data (Barron et al.,
# 2021). Both techniques were chosen due to their ability to efficiently handle
# complex data interactions and large amounts of data, with low amounts of
# assumptions. The Random Forest model was performed using the
# RandomForestRegressor() function from Scikit-learn. For the Deep Neural
# Network model, the Sequential() function from TensorFlow. The chosen optimizer
# was Adam for its adaptability, and one hundred epochs were performed. The
# same performance metrics were used as in the Poisson Regression.

# %% [markdown]
# ## Visual Tools

# %%
log_step("Visually Displaying Analyzed Data")
#logs time of step

# %%
plt.scatter(y_test, predictions_RF,color='green')
plt.plot([min(y_test), max(y_test)], [min(predictions_RF), max(predictions_RF)], linestyle='--',color='red', label='Perfect Prediction')
plt.title("Observed vs. Predicted")
plt.xlabel('Observed Values')
plt.ylabel('Predicted Values')
plt.legend()
plt.show()
plt.savefig("RF_observed_vs_predicted.png")
#plots and saves observed vs. predicted graph

# %%
plt.scatter(y_mean_test, predictions_RF_mean,color='green')
plt.plot([min(y_mean_test), max(y_mean_test)], [min(predictions_RF_mean), max(predictions_RF_mean)], linestyle='--', color='red', label='Perfect Prediction')
plt.title("Observed vs. Predicted (with Data's Outliers Removed by Standard Deviations Away")
plt.xlabel('Observed Values')
plt.ylabel('Predicted Values')
plt.legend()
plt.show()
plt.savefig("RF_observed_vs_predicted_mean.png")
#plots and saves observed vs. predicted graph (outliers removed through standard deviations)

# %%
plt.scatter(y__median_test, predictions_RF_median,color='green')
plt.plot([min(y__median_test), max(y__median_test)], [min(predictions_RF_median), max(predictions_RF_median)], linestyle='--', color='red', label='Perfect Prediction')
plt.title("Observed vs. Predicted (with Data's Outliers Removed by IQR)")
plt.xlabel('Observed Values')
plt.ylabel('Predicted Values')
plt.legend()
plt.show()
plt.savefig("RF_observed_vs_predicted_median.png")
#plots and saves graph of observed vs. predicted (with outliers removed through IQR)

# %%
plt.scatter(y__log_test, predictions_RF_log,color='green')
plt.plot([min(y__log_test), max(y__log_test)], [min(predictions_RF_log), max(predictions_RF_log)], linestyle='--', color='red', label='Perfect Prediction')
plt.title("Observed vs. Predicted (with Log Transformed Data)")
plt.xlabel('Observed Values')
plt.ylabel('Predicted Values')
plt.legend()
plt.show()
plt.savefig("RF_observed_vs_predicted_log.png")
#plots and saves graph with log transformed data

# %%
try:
    plt.scatter(y_test, predictions_RF)
    plt.savefig("plot.png")
    print("Graph generated and saved.")
except Exception as e:
    print(f"Plot failed: {e}")
# tests if plot created

# %% [markdown]
# A graph of the data was generated, meeting test expectations.

# %%
log_step("Visuals Analysis Displayed")
#prints that step was completed

# %% [markdown]
# ## Generating Reports

# %%
log_step("Generating Reports")
#logs time of step

# %% [markdown]
# ### Original Data

# %%
mse_RF = mean_squared_error(y_test, predictions_RF)
print(f'Mean Squared Error: {mse_RF}')

r2_RF = r2_score(y_test, predictions_RF)
print(f'R-squared: {r2_RF}')
#finds and prints R-squared and MSE

# %%
cv_results = cross_validate(regressor, X_train.values.reshape(-1, 1), y_train,
                            cv=5,
                            scoring=['neg_mean_squared_error', 'r2'],
                            return_train_score=True)

print("Cross Validate Mean Test MSE:", -cv_results['test_neg_mean_squared_error'])
print("Cross Validate Mean Test R²:", cv_results['test_r2'])
# performs cross validation and finds MSE and r-squared

# %%
with open("RF_model_report.txt", "w") as f:
    f.write("Random Forest Model Performance Report\n")
    f.write("========================\n")
    f.write(f"Mean Squared Error (MSE): " + str(mse_RF) + "\n")
    f.write(f"R-squared (R²): " + str(r2_RF) + "\n")
    f.write(f"Cross-Validation (MSE): " + str(cv_results['test_r2']) + "\n")
    f.write(f"Average CV Score (R²): "+ str(cv_results['test_neg_mean_squared_error']) + "\n")
# creates pdf of results

# %% [markdown]
# ### Data with Outliers Removed through Standard Deviations Away

# %%
mse_RF_mean = mean_squared_error(y_mean_test, predictions_RF_mean)
print(f'Mean Squared Error (with outliers removed through standard deivaitons): {mse_RF_mean}')
r2_RF_mean = r2_score(y_mean_test, predictions_RF_mean)
print(f'R-squared (with outliers removed through standard deviations): {r2_RF_mean}')
#finds and prinst MSE and r-squared of outliers removed through standard deviations

# %%
cv_results_mean = cross_validate(regressor_mean, X_mean_train.values.reshape(-1, 1), y_mean_train,
                            cv=5,
                            scoring=['neg_mean_squared_error', 'r2'],
                            return_train_score=True)

print("Cross Validate Mean Test MSE:", -cv_results_mean['test_neg_mean_squared_error'])
print("Cross Validate Mean Test R²:", cv_results_mean['test_r2'])
#performs cross validation and finds MSE and R-squared (outliers removed through standard deviations)

# %%
with open("RF_model_report_mean.txt", "w") as f:
    f.write("Random Forest Model Performance Report (with Data Outliers Removed through Standard Deviations Away)\n")
    f.write("========================\n")
    f.write(f"Mean Squared Error (MSE): " + str(mse_RF_mean) + "\n")
    f.write(f"R-squared (R²): " + str(r2_RF_mean) + "\n")
    f.write(f"Cross-Validation (MSE): " + str(cv_results_mean['test_r2']) + "\n")
    f.write(f"Average CV Score (R²): " + str(cv_results_mean['test_neg_mean_squared_error']) + "\n")
# creates pdf of results with data outliers removed through standard deviations away

# %% [markdown]
# ### Data with Outliers Removed through IQRs Away

# %%
mse_RF_median = mean_squared_error(y__median_test, predictions_RF_median)
print(f'Mean Squared Error (with outliers removed through IQR): {mse_RF_median}')
      
r2_RF_median = r2_score(y__median_test, predictions_RF_median)
print(f'R-squared (with outliers removed through IQR): {r2_RF_median}')
#finds and prints MSE and r-squared of data with outliers removed through IQR

# %%
cv_results_median = cross_validate(regressor_median, X_median_train.values.reshape(-1, 1), y_median_train,
                            cv=5,
                            scoring=['neg_mean_squared_error', 'r2'],
                            return_train_score=True)

print("Cross Validate Median Test MSE:", -cv_results_median['test_neg_mean_squared_error'])
print("Cross Validate Median Test R²:", cv_results_median['test_r2'])
# performs cross validation and finds MSE and r-squared values (data outliers removed through IQR)

# %%
with open("RF_model_report_median.txt", "w") as f:
    f.write("Random Forest Model Performance Report (with Data Outliers Removed through IQRs Away)\n")
    f.write("========================\n")
    f.write(f"Mean Squared Error (MSE): " + str(mse_RF_median) + "\n")
    f.write(f"R-squared (R²): " + str(r2_RF_median) + "\n")
    f.write(f"Cross-Validation (MSE): " + str(cv_results_median['test_r2']) + "\n")
    f.write(f"Average CV Score (R²): " + str(cv_results_median['test_neg_mean_squared_error']) + "\n")
# creates pdf of results with data outliers removed through IQRs away

# %% [markdown]
# ### Log Transformed Data

# %%
mse_RF_log = mean_squared_error(y__log_test, predictions_RF_log)
print(f'Mean Squared Error (with log transformed data): {mse_RF_log}')

r2_RF_log = r2_score(y__log_test, predictions_RF_log)
print(f'R-squared: {r2_RF_log}')
#finds and prints MSE and R-squared on log transformed data

# %%
cv_results_log = cross_validate(regressor_log, X_log_train.values.reshape(-1, 1), y_log_train,
                            cv=5,
                            scoring=['neg_mean_squared_error', 'r2'],
                            return_train_score=True)

print("Cross Validate Log Test MSE:", -cv_results_log['test_neg_mean_squared_error'])
print("Cross Validate Log Test R²:", cv_results_log['test_r2'])
# performs cross validation and finds MSE and R-squared on log transformed data

# %%
with open("RF_model_report_log.txt", "w") as f:
    f.write("Random Forest Model Performance Report (with Log Transformed Data)\n")
    f.write("========================\n")
    f.write(f"Mean Squared Error (MSE): " + str(mse_RF_log) + "\n")
    f.write(f"R-squared (R²): " + str(r2_RF_log) + "\n")
    f.write(f"Cross-Validation (MSE): " + str(cv_results_log['test_r2']) + "\n")
    f.write(f"Average CV Score (R²): " + str(cv_results_log['test_neg_mean_squared_error']) + "\n")
# creates pdf of results with log transformed data

# %%
def test_model_metrics(y_test, predictions, tolerance=1e-8):
    mse_2 = mean_squared_error(y_test, predictions_RF)
    r2_2 = r2_score(y_test, predictions_RF)
    assert np.isclose(mse_RF, mse_2, atol=tolerance), \
        f"MSE mismatch: expected {mse_2}, got {mse_RF}"

    assert np.isclose(r2_RF, r2_2, atol=tolerance), \
        f"R² mismatch: expected {r2_2}, got {r2_RF}"
    print("Model performance metrics validated successfully.")

mse_your_model = mean_squared_error(y_test, predictions_RF)
r2_your_model = r2_score(y_test, predictions_RF)
test_model_metrics(y_test, predictions_RF)

if isinstance(X_train, pd.Series):
    X_train = X_train.to_frame()

try:
    scores2 = cross_val_score(regressor, X_train, y_train, cv=5, scoring='r2')
    print("Cross-validation successful.")
    print("Cross-validation R² scores:", scores2)
    print("Mean CV R² score:", np.mean(scores2))
except Exception as e:
    print(f"Cross-validation failed: {e}")
# tests performance metrics

# %% [markdown]
# All performance metrics were able to be completed and generated successfully, meeting the test expectations.

# %%
log_step("Reports Generated")
#prints that step was completed

# %% [markdown]
# ## Visually Displaying the Analytical Pipeline

# %%
log_step("Visually Displaying Pipelines")
#prints that step was initialized

# %%
plot_tree(regressor.estimators_[0],
 filled=True,
 rounded=True,
 max_depth=3)
plt.title("Decision Tree from the Random Forest")
plt.show()
# graphs structure of the model

# %%
log_step("Pipelines Visually Displayed")
#prints that step was completed

# %%
log_step("Stepwise Execution Complete")
log_step("Full Pipeline Execution Complete")
#finishes logging the steps in the data

# %% [markdown]
# ## Interpreting the Data

# %% [markdown]
# Random Forest modeling did show more promise in its results. The model based on the original data produced a higher R-squared value of -0.18012783493528484. However, the mean squared error was still high, at 48,222,758,103,529.266. Cross validation showed great differences in MSE and R-squared values. The observed against predicted values had some values gathered around the diagonal through the graph, but more were distributed away from the diagonal. The model based on removing outliers three standard deviations away resulted in a lower mean squared error, (14,747,701,344,638.822), but it was still large, and the R-squared improved to -0.3859638774809353. Cross validation results were more consistent. The observed against predicted values graph did have values more disperse than the original, but still few were situated around a diagonal. As for the data set with the outliers removed using the interquartile range, the mean squared error was large, but still better than the original data's, at 9,303,333,520,386.098. It's R-squared value was -6.108212974529689, which suggests an error with the model as R-squared values should be between -1 and 1. Interestingly, cross validation showed other models having R-squared values ranging from -0.277 to -0.295, and MSEs similar to that of the model created. It is possible that the created model is an outlier. Additionally, its predicted against observed values were mostly situated more towards the bottom of the graph. The model generated from the logarithmically transformed data received the best overall results, with a mean squared error of 49.05173430731382 and an R-squared value of -0.13586517945585053. Cross validation did have similar MSEs and R-squared values. While there was still variation in the data points, the values observed against predicted graph do appear to be better distributed along the forty-five-degree center of the graph. Further modifications to this model could result in greater performance.
# 
# Overall, the logarithmic models appear to be the best way to handle outliers in this large data set. However, across various modeling, Poisson Regression, Random Forest, and DNN models had similar results with logarithmic transformed data. Unfortunately, no models generated results strong enough to make reliable decisions upon. Given this, the next steps for this research is to implement feature engineering techniques to attempt to improve model performance. If this does not improve the results, then local data may be more appropriate when creating predictive models. The former will be performed in a new file, as well as the later if poor results are received again. Insights could potentially be gained on predicting the vaccination needs for future purposes, as well as providing information to policy makers on potential effective techniques in limiting the deaths due to the virus.

# %% [markdown]
# ## GUI Elements

# %% [markdown]
# The main GUI elements implemented were in the early graphs while exploring
# the data. As the main purpose of this product is to share results and knowledge
# on model performance for pandemic related data. These graphs included Box
# Plots for COVID-19 vaccinations and deaths, were a drop down box allowed for
# specific locations or the entirety of the world data was viewed. The box plot is
# important in outlier identification. This was also applied to histograms and line
# plots of the COVID-19 doses and related deaths. Histograms are important in
# understanding the structure of the data, while the line plot could be utilized to
# indetify potential trends in the data. If an individual was interested in just local
# information, or how this compared to another area or the entire world data, it is
# now visually available to them for visualizing outliers, data structure, and trends.
# Another visual aid provided was the COVID-19 vaccinations and deaths shown on
# a map of the world. As the daily rates did not appear to add much context,
# cumulative counts were added and applied as a drop down option for the graph.
# This allows for people to see where potential areas of high or low activity for
# vaccinations administered or deaths due to the virus. All utlizied the
# update_layout() function from plotly (Plotly, n.d.). Otherwise, the product is fairly
# straight-forward, as analysis models and their results are printed. The additions
# enhance the user experience by providing a detailed and big picture viewpoints
# of the data. This could aid in analysis by identifying any areas that appear
# significant or as potential outliers to the user.

# %% [markdown]
# ## Security

# %% [markdown]
# At this time, no security systems have been developed for the product. The data utilized is made publicly available and contains no personal identifiable information. As for the processing and modeling of the data, the purpose is for educational use, only. Testing of functions is performed to ensure all are appropriately working. If anyone were to make harmful changes to these, then they would only be preventing themselves from gaining insightful results.
# 
# If users upload data that contains personal information or develop their own product that is used for important decision making, then it is recommended that more measures are included for security. Additionally, any externally uploaded data should be fully preprocessed, as the current data was. The only exception is no implementations were performed for analyzing that the data type was appropriate for the data, as this must be examined and changed on an individual basis. All cleaning and preprocessing steps should be examined with introduction of new data, as well as analyzing the newly uploaded data for validity.
# 
# There is a risk that others could make changes to the models, and therefore, change the integrity of the model. It is recommended to all users to review the models for appropriate structure prior to implementation.

# %% [markdown]
# ## Revisions

# %% [markdown]
# New additions to the product included more references, addressing security, creating a pop-up to allow url data uploads, adding tests to each function, and a help guide at the top of each file.
# 
# Updates to the files included a more in depth exploration of potential seasonality and trends in the data, fixing code to actually use the split of the train and test data, and updating codes so no warnings or error messages were received.
# 
# Failed attempts at revisions were introducing more feature engineering techniques for Poisson Regression, Random Forest, and DNN modeling. Introducing seasonality did not show increase performance in the models. As previous research has shown more success at predicting with more localized data, it is recommended to take this approach when analyzing pandemic related data.
# 
# From this information and the poor performance across all models, future goals are to attempt to rectify prior errors at improving model performance in new files. If these still return poor results, an exploration of learning data at a more local level will be the new objective to compare performance against.
# 
# For adherence to industry standards, it is imperative to have reproducibile and replicabile results (Gîrjău, Horton, & Pruim, 2023). Given this information, it is recommended to not make decisions from any of the current models. Any further implementations should focus on the logarithmic transformed data set. Additionally, the elimination of errors and warning messages follows best practices. It is also recommended to learn from the work of others. Prior work was used when devloping the models, as seen in the inserted referneces.

# %% [markdown]
# ## References 

# %% [markdown]
# Alroy-Preis, S., Angulo, F. Anis, E., Brooks, N., Haas, E. J., Jodar, :., Khan, F., Levy, Y., McLaughlin, J. M., Mircus, G., Pan, K., Singer, S. R., Smaja, M., Southern, J., & Swerdlow, D. L. (2021). Impact and effectiveness of mRNA BNT162b2 vaccine against SARS-CoV-2 infections and COVID-19 cases, hospitalisations, and deaths following a nationwide vaccination campaign in Israel: an observational study using national surveillance data. Lancet, 397(10287), 1819-1829. doi: 10.1016/S0140-6736(21)00947-8 
# 
# Appel, C., Beltekian, D., Dattani, S., Gavrilov, D., Giattino, C., Hasell, J.,
# Macdonald, B., Mathieu, E., Ortiz-Ospina, E., Ritchie, H., Rodes-Guirao, L., &
# Roser, M. (2025). COVID-19 pandemic [Data set]. Our World in Data.
# https://ourworldindata.org/coronavirus
# 
# Barbeira, P. B., Bartolomeu, M. L., Castelli, J. M., Del Valle Juarez, M., Esperatti, M., Fuentes, N., Galligani, G., Giovacchini, C. M., Iummato, L. E., Laurora, M., Pennini, V., Pesce, M., Rearte, A. Rearte, R., Santoro, A., Tarragona, S., & Vizzotti, C. (2022). Effectiveness of rAd26-rAd5, ChAdOx1 nCoV-19, and BBIBP-CorV vaccines for risk of infection with SARS-CoV-2 and death due to COVID-19 in people older than 60 years in Argentina: a test-negative, case-control, and retrospective longitudinal study. Lancet, 399(10331), 1254-1264. doi: 10.1016/S0140-6736(22)00011-3 
# 
# Barron, J. A., Buenrostro-Mariscal, R., Crossa, J., Montesinos-Lopez, A.
# Montesinos-Lopez, J. C., Montesinos-Lopez, O. A., & Salazar, E. (2021).
# Application of a Poisson deep neural network model for the prediction of count
# data in genome-based prediction. The Plant Genome, 14(3).
# https://doi.org/10.1002/tpg2.20118
# 
# Brownlee, J. (2022). Your first deep learning project in Python with Keras step-by-step. *Machine Learning Mastery.* https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/
# 
# Elliott, L., Loomis, D., & Richardson, D. B. (2005). Poisson regression analysis of
# ungrouped data. Occupational and Environmental Medicine, 62, 325-329. DOI:
# 10.1136/oem.2004.017459
# 
# Fandohan, A. B., Kakaï, R. G., & Mushaglusa, C. Z. (2022). Random forest in count
# data modelling: An analysis of the influence of data features and overdispersion
# on regression performance. Journal of Probability and Statistics, 1.
# https://doi.org/10.1155/2022/2833537
# 
# GeeksforGeeks. (2025). Ranom forest regression in Python. https://www.geeksforgeeks.org/random-forest-regression-in-python/ 
# 
# Gîrjău, M., Horton, N. J., & Prium, R. (2023). Fostering better coding practices for data scientists. HDSR. https://hdsr.mitpress.mit.edu/pub/8wsiqh1c/release/4
# 
# Katla, N. (2020). Poisson regression implementation- Python. *Medium.* https://medium.com/@kn12/poisson-regression-implementation-python-28d15e95dc15
# 
# Liu, J. (2024). Navigating the financial landscape: The power and limitations of
# the ARIMA model. Highlights in Science, Engineering and Technology, 88, 747-752. https://drpress.org/ojs/index.php/HSET/article/view/19082/18645
# 
# National Cancer Institute. (2023). Cleaning data: The basics. Center for
# Biomedical Informatics and Information Technology.
# https://datascience.cancer.gov/training/learn-data-science/clean-data-basics
# 
# The Pennsylvania State University. (n.d.). 9: Poisson Regression.
# https://online.stat.psu.edu/stat504/book/export/html/782#:~:text=Interpretations,tabletop%20of%20a%20certain%20area
# 
# Plotly. (n.d.). Creating and updating figures in Python.
# https://plotly.com/python/creating-and-updating-figures/#updating-figures
# 
# Sarahjane3102. (2022). How to split the dataset With scikit-learn’s train_test_split() function *GeeksforGeeks.* https://www.geeksforgeeks.org/how-to-split-the-dataset-with-scikit-learns-train_test_split-function/


